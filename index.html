<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ke  Wang</title>
    <meta name="author" content="Ke  Wang">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.ico">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://kewang0622.github.io/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Social Icons -->
          <div class="navbar-brand social">
            <a href="mailto:%6B%65%77%61%6E%67@%62%65%72%6B%65%6C%65%79.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=Iz3m3v4AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/KeWang0622" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/ke-wang-32705a16a" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/KewangKe" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a>
            

          </div>
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/service/">service</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
            <span style="font-weight: 500">Ke</span>
              
              Wang  <br class="d-md-none">(王
                <span style="font-weight: 500">可</span>)
          </h1>
          <p class="desc"></p>
        </header>

        <article>
          <div class="profile float-left">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kewang-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kewang-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kewang-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/kewang.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="kewang.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

            <div class="address d-none d-md-block">
              <p>Samsung Research America</p> <p>MPI Lab</p> <p>6625 Excellence Way</p> <p>Plano, Texas, 75023</p>

            </div>
          </div>

          <div class="clearfix">
            <p>I am currently a senior research engineer at Samsung Research America (SRA), MPI Lab, working on real-world computational imaging and computer vision problems. I obtained my Ph.D. degree from Electrical Engineering and Computer Sciences at UC Berkeley, working with <a href="http://people.eecs.berkeley.edu/~mlustig/" rel="external nofollow noopener" target="_blank">Prof. Miki Lustig</a> and <a href="https://web.eecs.umich.edu/~stellayu/" rel="external nofollow noopener" target="_blank">Prof. Stella Yu</a>. I was a member of <a href="https://bair.berkeley.edu/" rel="external nofollow noopener" target="_blank">Berkeley Artificial Intelligence Research (BAIR)</a>. I graduated with honor from the department of <a href="http://www.med.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">Biomedical Engineering</a>in <a href="http://www.tsinghua.edu.cn/publish/thu2018en/index.html/" rel="external nofollow noopener" target="_blank">Tsinghua University</a>. My research interests lie in <strong>computational imaging, deep learning, signal processing, inverse problem, medical imaging and computer vision</strong>. I am an enthusiast of science, engineering, music, ice skating, rock climbing and everything related to medicine and healthcare! My name in Chinese is 王可.</p>

<p>I did a wonderful  internship at Adobe Emerging Products Group in the summer of 2021 (Work deployed at PhotoShope Camera)!</p>

<p>I interned at Adobe Research as a research scientist intern from May 2022 to March 2023. I was fortunate to work with the awesome <a href="http://mgharbi.com/" rel="external nofollow noopener" target="_blank">Michaël Gharbi</a>, <a href="https://sites.google.com/site/hezhangsprinter" rel="external nofollow noopener" target="_blank">He Zhang</a>, <a href="https://likesum.github.io/" rel="external nofollow noopener" target="_blank">Zhihao Xia</a>, and <a href="https://research.adobe.com/person/eli-shechtman/" rel="external nofollow noopener" target="_blank">Eli Shechtman</a>.</p>

<p>Feel free to reach me at <strong>kewang [at] berkeley [dot] edu</strong>.</p>

<!--
Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.test

Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.
-->

          </div>

          <!-- News -->
          <h2><a href="/news/" style="color: inherit;">news</a></h2>          <div class="news">
            <div class="table-responsive" style="max-height: 60vw">
              <table class="table table-sm table-borderless">
              
                <tr>
                  <th scope="row">Jun 30, 2023</th>
                  <td>
                    Our image harmonization work (<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Semi-Supervised_Parametric_Real-World_Image_Harmonization_CVPR_2023_paper.pdf" rel="external nofollow noopener" target="_blank">Semi-supervised Parametric Real-world Image Harmonization</a>) is presented at CVPR 2023. <a href="https://kewang0622.github.io/sprih/" rel="external nofollow noopener" target="_blank">[Project page]</a> <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Semi-Supervised_Parametric_Real-World_Image_Harmonization_CVPR_2023_paper.pdf" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://www.youtube.com/watch?v=SGAyDbJPyps" rel="external nofollow noopener" target="_blank">[Video]</a> <a href="https://github.com/adobe/PIH" rel="external nofollow noopener" target="_blank">[Code]</a> <a href="cvpr23_poster_8236.pdf">[Poster]</a>
<!-- 
[https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Semi-Supervised_Parametric_Real-World_Image_Harmonization_CVPR_2023_paper.pdf \[Paper\]][https://www.youtube.com/watch?v=SGAyDbJPyps \[Video\]][https://github.com/adobe/PIH \[Code\]][cvpr23_poster_8236.pdf \[Poster\]] -->


                  </td>
                </tr>
                <tr>
                  <th scope="row">Jun 19, 2023</th>
                  <td>
                    Our paper <strong>High-fidelity Direct Contrast Synthesis from MR Fingerprinting</strong> was accepted by MRM is now published online! Please check it out! <a href="https://onlinelibrary.wiley.com/doi/10.1002/mrm.29766" rel="external nofollow noopener" target="_blank">[Paper]</a>
<!-- 
[https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Semi-Supervised_Parametric_Real-World_Image_Harmonization_CVPR_2023_paper.pdf \[Paper\]][https://www.youtube.com/watch?v=SGAyDbJPyps \[Video\]][https://github.com/adobe/PIH \[Code\]][cvpr23_poster_8236.pdf \[Poster\]] -->


                  </td>
                </tr>
                <tr>
                  <th scope="row">Jun 1, 2023</th>
                  <td>
                    I join <a href="https://sra.samsung.com/" rel="external nofollow noopener" target="_blank">Samsung Research America (SRA)</a> as a senior research engineer, working on real-worled computational imaging and computer vision! Lets keep making impacts!


                  </td>
                </tr>
                <tr>
                  <th scope="row">May 12, 2023</th>
                  <td>
                    Graduation time! I offically obtained my Ph.D degree from EECS, UC Berkeley! Go Bears! My theis <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-178.html" rel="external nofollow noopener" target="_blank">Magnetic Resonance Image Reconstruction with Greater Fidelity and Efficiency</a> is available!


                  </td>
                </tr>
                <tr>
                  <th scope="row">Jan 1, 2023</th>
                  <td>
                    I will be serving as reviewer for MICCAI 2023, Neurips 2023, Siggraph Asia 2023, Siggraph 2023.


                  </td>
                </tr>
                <tr>
                  <th scope="row">May 30, 2022</th>
                  <td>
                    I presented our work on <strong>Rigorous Uncertainty Estimation for MRI Reconstruction</strong> at ISMRM 2022 as an oral presentation. Manuscript and abstract is available upon request.

<!-- I will be serving as reviewer for MICCAI 2023, Neurips 2023, Siggraph Asia 2023, Siggraph 2023. -->


                  </td>
                </tr>
                <tr>
                  <th scope="row">Apr 30, 2022</th>
                  <td>
                    Our UFLoss paper titled <strong>High fidelity deep learning-based MRI reconstruction with instance-wise discriminative feature matching loss</strong> was accecpted by MRM and is now published online! Please check it out! <a href="https://onlinelibrary.wiley.com/doi/10.1002/mrm.29227" rel="external nofollow noopener" target="_blank">[paper]</a> <a href="https://cds.ismrm.org/protected/20MPresentations/videos/dcvz/0994.htm" rel="external nofollow noopener" target="_blank">[talk]</a> <a href="https://github.com/mikgroup/UFLoss" rel="external nofollow noopener" target="_blank">[code]</a>

<!-- I will be serving as reviewer for MICCAI 2023, Neurips 2023, Siggraph Asia 2023, Siggraph 2023. -->


                  </td>
                </tr>
                <tr>
                  <th scope="row">Feb 20, 2022</th>
                  <td>
                    Three abstracts (1 first-authored and 2 co-authored) were accepted by ISMRM 2022 as oral presentations!

<!-- I will be serving as reviewer for MICCAI 2023, Neurips 2023, Siggraph Asia 2023, Siggraph 2023. -->


                  </td>
                </tr>
                <tr>
                  <th scope="row">Feb 1, 2022</th>
                  <td>
                    <!-- Three abstracts (1 first-authored and 2 co-authored) were accepted by ISMRM 2022 as oral presentations! -->
Our Data Crimes paper with title <strong>Implicit data crimes: Machine learning bias arising from misuse of public data</strong> was accpeted for publication in PNAS! More infromation and details for this paper are avaible on <a href="https://www.efratshimron.com/efrat-shimron-home" rel="external nofollow noopener" target="_blank">Efrat’s website</a>.

<!-- I will be serving as reviewer for MICCAI 2023, Neurips 2023, Siggraph Asia 2023, Siggraph 2023. -->


                  </td>
                </tr>
                <tr>
                  <th scope="row">Sep 30, 2021</th>
                  <td>
                    <!-- Three abstracts (1 first-authored and 2 co-authored) were accepted by ISMRM 2022 as oral presentations! -->
I presented our work on <strong>Memory-efficient Learning for High-dimensional MRI Reconstruction</strong> at <a href="https://miccai2021.org/en/" rel="external nofollow noopener" target="_blank">MICCAI 2021</a>. Date &amp; Time: <em>September 29th (Wednesday), 09:30 - 11:00 (UTC)</em>. Welcome to check it out! <a href="https://arxiv.org/abs/2103.04003" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://arxiv.org/abs/2103.04003" rel="external nofollow noopener" target="_blank">[Poster]</a> <a href="https://www.youtube.com/watch?v=zkCjlOnURSc" rel="external nofollow noopener" target="_blank">[Video]</a>

<!-- I will be serving as reviewer for MICCAI 2023, Neurips 2023, Siggraph Asia 2023, Siggraph 2023. -->


                  </td>
                </tr>
              </table>
            </div>
          </div>

          <!-- Latest posts -->
          

          <!-- Selected papers -->
          <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2>
          <div class="publications">
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="thesisjpg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/thesis.jpg"><div id="thesisjpg-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('thesisjpg-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="thesisjpg-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("thesisjpg-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('thesisjpg');
      var modalImg = document.getElementById("thesisjpg-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="phdthesiskw" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">PhD Thesis: Magnetic Resonance Imaging with Greater Fidelity and Efficiency</div>
    <!-- Author -->
    <div class="author">
      

      <em>Ke Wang</em>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>University of California, Berkeley</em>, 2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-178.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Magnetic Resonance Imaging (MRI) is an effective medical imaging modality, offering excellent soft tissue contrast, versatile orientation capabilities, and no ionizing radiation exposure. However, its inherent physics constraints lead to time-consuming data acquisition and prolonged scan times. To reduce scan time, recently, deep learning (DL) has achieved notable success in reconstructing high-quality MR images from under-sampled data, surpassing conventional non-learned approaches. Despite this progress, challenges such as hand-crafted loss functions, high computational costs, and limited training data remain. In this dissertation, I will present a series of projects focused on enhancing fidelity and efficiency in MRI reconstruction. I will first introduce a supervised learning method that synthesizes multi-contrast MR images from a single MRF scan. Next, I will present a novel feature loss designed to preserve perceptual similarity, demonstrating its effectiveness in high-fidelity image reconstruction. Following that, I will touch upon memory-efficient learning for high-dimensional MRI reconstruction and present a novel framework for rigorous uncertainty estimation. Lastly, I will introduce a novel complex-valued representation tailored for tasks with limited training data.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="afterjpeg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/after.jpeg"><div id="afterjpeg-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('afterjpeg-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="afterjpeg-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("afterjpeg-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('afterjpeg');
      var modalImg = document.getElementById("afterjpeg-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="wang2023semi" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Semi-supervised Parametric Real-world Image Harmonization</div>
    <!-- Author -->
    <div class="author">
      

      <em>Ke Wang</em>, Michaël Gharbi, He Zhang, Zhihao Xia, and
      <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Eli Shechtman' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://www.youtube.com/watch?v=SGAyDbJPyps" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a>
      <a href="https://kewang0622.github.io/sprih/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project Page</a>
      <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Semi-Supervised_Parametric_Real-World_Image_Harmonization_CVPR_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
      <a href="https://github.com/adobe/PIH/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      <a href="http://127.0.0.1:4000/cvpr23_poster_8236.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Learning-based image harmonization techniques are usually trained to undo synthetic random global transformations applied to a masked foreground in a single ground truth photo. This simulated data does not model many of the important appearance mismatches (illumination, object boundaries, etc.) between foreground and background in real composites, leading to models that do not generalize well and cannot model complex local changes. We propose a new semi-supervised training strategy that addresses this problem and lets us learn complex local appearance harmonization from unpaired real composites, where foreground and background come from different images. Our model is fully parametric. It uses RGB curves to correct the global colors and tone and a shading map to model local variations. Our method outperforms previous work on established benchmarks and real composites, as shown in a user study, and processes high-resolution images interactively.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="mrfjpg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/mrf.jpg"><div id="mrfjpg-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('mrfjpg-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="mrfjpg-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("mrfjpg-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('mrfjpg');
      var modalImg = document.getElementById("mrfjpg-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="wang2023high" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">High-fidelity direct contrast synthesis from magnetic resonance fingerprinting</div>
    <!-- Author -->
    <div class="author">
      

      <em>Ke Wang</em>, Mariya Doneva, Jakob Meineke, Thomas Amthor, and
      <span class="more-authors" title="click to view 5 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '5 more authors' ? 'Ekin Karasan, Fei Tan, Jonathan I Tamir, Stella X Yu, Michael Lustig' : '5 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">5 more authors</span>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Magnetic Resonance in Medicine</em>, 2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.29766" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="http://arxiv.org/abs/https://arxiv.org/abs/2212.10817" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Magnetic Resonance Fingerprinting (MRF) is an efficient quantitative MRI technique that can extract important tissue and system parameters such as T1, T2, B0, and B1 from a single scan. This property also makes it attractive for retrospectively synthesizing contrast-weighted images. In general, contrast-weighted images like T1-weighted, T2-weighted, etc., can be synthesized directly from parameter maps through spin-dynamics simulation (i.e., Bloch or Extended Phase Graph models). However, these approaches often exhibit artifacts due to imperfections in the mapping, the sequence modeling, and the data acquisition. Here we propose a supervised learning-based method that directly synthesizes contrast-weighted images from the MRF data without going through the quantitative mapping and spin-dynamics simulation. To implement our direct contrast synthesis (DCS) method, we deploy a conditional Generative Adversarial Network (GAN) framework and propose a multi-branch U-Net as the generator. The input MRF data are used to directly synthesize T1-weighted, T2-weighted, and fluid-attenuated inversion recovery (FLAIR) images through supervised training on paired MRF and target spin echo-based contrast-weighted scans. In-vivo experiments demonstrate excellent image quality compared to simulation-based contrast synthesis and previous DCS methods, both visually as well as by quantitative metrics. We also demonstrate cases where our trained model is able to mitigate in-flow and spiral off-resonance artifacts that are typically seen in MRF reconstructions and thus more faithfully represent conventional spin echo-based contrast-weighted images.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="uflossjpg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/ufloss.jpg"><div id="uflossjpg-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('uflossjpg-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="uflossjpg-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("uflossjpg-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('uflossjpg');
      var modalImg = document.getElementById("uflossjpg-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="wang2022high" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">High fidelity deep learning-based MRI reconstruction with instance-wise discriminative feature matching loss</div>
    <!-- Author -->
    <div class="author">
      

      <em>Ke Wang</em>, Jonathan I Tamir, Alfredo De Goyeneche, Uri Wollner, and
      <span class="more-authors" title="click to view 3 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '3 more authors' ? 'Rafi Brada, Stella X Yu, Michael Lustig' : '3 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">3 more authors</span>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Magnetic Resonance in Medicine</em>, 2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.29227" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="http://arxiv.org/abs/https://arxiv.org/abs/2108.12460" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
      <a href="https://github.com/mikgroup/UFLoss" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Purpose: To improve reconstruction fidelity of fine structures and textures in deep learning (DL) based reconstructions.
  Methods: A novel patch-based Unsupervised Feature Loss (UFLoss) is proposed and incorporated into the training of DL-based reconstruction frameworks in order to preserve perceptual similarity and high-order statistics. The UFLoss provides instance-level discrimination by mapping similar instances to similar low-dimensional feature vectors and is trained without any human annotation. By adding an additional loss function on the low-dimensional feature space during training, the reconstruction frameworks from under-sampled or corrupted data can reproduce more realistic images that are closer to the original with finer textures, sharper edges, and improved overall image quality. The performance of the proposed UFLoss is demonstrated on unrolled networks for accelerated 2D and 3D knee MRI reconstruction with retrospective under-sampling. Quantitative metrics including NRMSE, SSIM, and our proposed UFLoss were used to evaluate the performance of the proposed method and compare it with others.
  Results: In-vivo experiments indicate that adding the UFLoss encourages sharper edges and more faithful contrasts compared to traditional and learning-based methods with pure l2 loss. More detailed textures can be seen in both 2D and 3D knee MR images. Quantitative results indicate that reconstruction with UFLoss can provide comparable NRMSE and a higher SSIM while achieving a much lower UFLoss value.
  Conclusion: We present UFLoss, a patch-based unsupervised learned feature loss, which allows the training of DL-based reconstruction to obtain more detailed texture, finer features, and sharper edges with higher overall image quality under DL-based reconstruction frameworks.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="miccaijpg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/miccai.jpg"><div id="miccaijpg-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('miccaijpg-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="miccaijpg-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("miccaijpg-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('miccaijpg');
      var modalImg = document.getElementById("miccaijpg-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="wang2021memory" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Memory-efficient learning for high-dimensional mri reconstruction</div>
    <!-- Author -->
    <div class="author">
      

      <em>Ke Wang</em>, Michael Kellman, Christopher M Sandino, Kevin Zhang, and
      <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Shreyas S Vasanawala, Jonathan I Tamir, Stella X Yu, Michael Lustig' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>In Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part VI 24</em>
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://www.youtube.com/watch?v=zkCjlOnURSc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a>
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-87231-1_45" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="http://arxiv.org/abs/https://arxiv.org/abs/2103.04003" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
      <a href="https://github.com/mikgroup/MEL_MRI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      <a href="/assets/pdf/MICCAI.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Deep learning (DL) based unrolled reconstructions have shown state-of-the-art performance for under-sampled magnetic resonance imaging (MRI). Similar to compressed sensing, DL can leverage high-dimensional data (e.g. 3D, 2D+time, 3D+time) to further improve performance. However, network size and depth are currently limited by the GPU memory required for backpropagation. Here we use a memory-efficient learning (MEL) framework which favorably trades off storage with a manageable increase in computation during training. Using MEL with multi-dimensional data, we demonstrate improved image reconstruction performance for in-vivo 3D MRI and 2D+time cardiac cine MRI. MEL uses far less GPU memory while marginally increasing the training time, which enables new applications of DL to high-dimensional MRI.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="uncertaintypng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/uncertainty.png"><div id="uncertaintypng-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('uncertaintypng-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="uncertaintypng-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("uncertaintypng-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('uncertaintypng');
      var modalImg = document.getElementById("uncertaintypng-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="kwang20221" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Rigorous Uncertainty Estimation for MRI Reconstruction</div>
    <!-- Author -->
    <div class="author">
      

      <em>Ke Wang</em>, Anastasios Angelopoulos, Alfredo De Goyeneche, Amit Kohli, and
      <span class="more-authors" title="click to view 4 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '4 more authors' ? 'Efrat Shimron, Stella Yu, Jitendra Malik, Michael Lustig' : '4 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">4 more authors</span>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>In Proc. Intl. Soc. Mag. Reson. Med</em>, 2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://archive.ismrm.org/2022/0749.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Deep-learning (DL)-based MRI reconstructions have shown great potential to reduce scan time while maintaining diagnostic image quality. However, their adoption has been plagued with fears that the models will hallucinate or eliminate important anatomical features. To address this issue, we develop a framework to identify when and where a reconstruction model is producing potentially misleading results. Specifically, our framework produces confidence intervals at each pixel of a reconstruction image such that 95% of these intervals contain the true pixel value with high probability. In-vivo 2D knee and brain reconstruction results demonstrate the effectiveness of our proposed uncertainty estimation framework.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="pnasjpg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/pnas.jpg"><div id="pnasjpg-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('pnasjpg-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="pnasjpg-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("pnasjpg-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('pnasjpg');
      var modalImg = document.getElementById("pnasjpg-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="shimron2022implicit" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Implicit data crimes: Machine learning bias arising from misuse of public data</div>
    <!-- Author -->
    <div class="author">
      

      Efrat Shimron, Jonathan I Tamir, <em>Ke Wang</em>, and Michael Lustig</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Proceedings of the National Academy of Sciences</em>, 2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://www.youtube.com/watch?v=sGJQqqpOwNs&amp;t=68s&amp;ab_channel=ESMRMB" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a>
      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9060447/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
      <a href="http://arxiv.org/abs/https://arxiv.org/abs/2109.08237" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
      <a href="https://github.com/mikgroup/data_crimes" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Although open databases are an important resource in the current deep learning (DL) era, they are sometimes used “off label”: Data published for one task are used to train algorithms for a different one. This work aims to highlight that this common practice may lead to biased, overly optimistic results. We demonstrate this phenomenon for inverse problem solvers and show how their biased performance stems from hidden data-processing pipelines. We describe two processing pipelines typical of open-access databases and study their effects on three well-established algorithms developed for MRI reconstruction: compressed sensing, dictionary learning, and DL. Our results demonstrate that all these algorithms yield systematically biased results when they are naively trained on seemingly appropriate data: The normalized rms error improves consistently with the extent of data processing, showing an artificial improvement of 25 to 48% in some cases. Because this phenomenon is not widely known, biased results sometimes are published as state of the art; we refer to that as implicit “data crimes.” This work hence aims to raise awareness regarding naive off-label usage of big data and reveal the vulnerability of modern inverse problem solvers to the resulting bias.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="tcjpg" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/tc.jpg"><div id="tcjpg-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('tcjpg-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="tcjpg-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("tcjpg-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('tcjpg');
      var modalImg = document.getElementById("tcjpg-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="nan2019non" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Non-Invasive Remote Temperature Monitoring Using Microwave-Induced Thermoacoustic Imaging</div>
    <!-- Author -->
    <div class="author">
      

      Hao Nan, Aidan Fitzpatrick, <em>Ke Wang</em>, and Amin Arbabian</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://pubmed.ncbi.nlm.nih.gov/31947301/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Non-invasive temperature monitoring of tissue at depth in real-time is critical to hyperthermia therapies such as high-intensity focused ultrasound. Knowledge of temperature allows for monitoring treatment as well as providing real-time feedback to adjust deposited power in order to maintain safe and effective temperatures. Microwave-induced thermoacoustic (TA) imaging, which combines the conductivity/dielectric contrast of microwave imaging with the resolution of ultrasound, shows potential for estimating temperature non-invasively in real-time by indirectly measuring the temperature dependent parameters from reconstructed images. In this work, we study the temperature dependent behavior of the generated pressure in the TA effect and experimentally demonstrate simultaneous imaging and temperature monitoring using TA imaging. The proof-of-concept experiments demonstrate millimeter spatial resolution while achieving degree-level accuracy.</p>
    </div>
  </div>
</div>
</li>
</ol>
          </div>


          <!-- Social -->
            <div class="social">
              <div class="contact-icons">
                <a href="mailto:%6B%65%77%61%6E%67@%62%65%72%6B%65%6C%65%79.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=Iz3m3v4AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/KeWang0622" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/ke-wang-32705a16a" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/KewangKe" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a>
            

              </div>

              <div class="contact-note">
                
              </div>

            </div>
        </article>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Ke  Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.
Last updated: August 20, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', '');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
